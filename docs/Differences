Goals achieved with rewrite:
- No more memory leak in main process.
- No more locked up event bus via unix sockets (uses MongoDB to pass all data).
- Can stop/restart disbatchd process any time without affecting running tasks.
- Can update plugins at any time without restarting disbatchd.
- Independent web server.


Backwards compatibility for existing deployments:
- Can replace v3 of Disbatch with v4 with no* changes to database, and minimal
  back-compat changes to plugin.
- Can run both v3 and v4 against the same unauthenticated database.
- CANNOT pass Perl data structures (only JSON is allowed) to 'queue search' nor
  'queue tasks'. That was a horrible idea.
- The "Backfill" feature has been removed - a web server thread handles this
  (creating 100k tasks at once only took 12 seconds on my 13" rMBP).
- The "Preemptive" setting has been removed.
- The "enclosure" command has been removed.
- The main process, the web server, and the task runner all have their own
  permission models if using authentication instead of sharing one account.


Changes:
- To keep the code simple, as much as possible is by convention instead of
  config (collection names, node, ...).
- No need to have a file in etc/disbatch/disbatch.d/ to define a plugin.
- Only the ::Task part of the plugin is needed. Its parent is unused.
- bin/disbatchd instead of bin/disbatchd.pl
- etc/disbatch/config.json instead of etc/disbatch/disbatch.ini
  - most config will go into a 'config' collection.
- The disbatch-log4perl.conf file no longer used (automatically generated
  settings, can be overwritten in the config file)
- Task stdout and stderr are now written to (mostly-compatible) GridFS
  documents.
- To define a queue, the type must already be used in another queue, or listed
  in 'plugins' in the config


New:
- can limit a node to a maximum number of tasks to run (value goes in the nodes
  collection documents)


Upgrading:
- Rename the tasks and queues collections to 'tasks' and 'queues' if they have a
  different name.
- If there is already a collection 'config', rename it to something else.
- Put MongoDB connection details in etc/disbatch/config.json
- Setup Authentication (optional):
  - Put datbase user passwords in etc/disbatch/config.json
  - Run bin/disbatch-create-users
- Setup config collection:
  - this is done automatically if not defined: creates 2 documents with labels
    'production' and 'development'
  - production will be set to active unless the config file has a
    'default_config' value of something else
  - only one document in this collection can have 'active' set to true (a unique
    and sparse index)
  - each document must have a unique 'label'
  - the document can be changed while disbatchd is running, and even a different
    document can be set to active (but be careful because it searches for the
    active document every second)
- Modify plugin (these modifications allow plugin to still work on v3):
  - remove:
    use Synacor::Disbatch::Task;
    use Synacor::Disbatch::Engine;
    our @ISA=qw(Synacor::Disbatch::Task);
  - add (the warning is optional):
    warn "Synacor::Disbatch::Task not found\n"
        unless eval 'use base "Synacor::Disbatch::Task"; 1';
    warn "Synacor::Disbatch::Engine not found\n"
        unless eval 'use Synacor::Disbatch::Engine; 1';
  - append to any $Synacor::Disbatch::Engine::EventBus call (report_task_done):
    if defined $Synacor::Disbatch::Engine::EventBus
  - return:
    {status => $status, stdout => $stdout, stderr => $stderr};
